% Referencias bibliográficas para TFG
% Vision Transformers para Detección de Anomalías Industriales
% Generado: Octubre 2024

% ============================================================================
% SURVEYS Y FUNDAMENTOS
% ============================================================================

@article{khan2024survey,
  title     = {A Survey of the Self Supervised Learning Mechanisms for Vision Transformers},
  author    = {Khan, Asifullah and Sohail, Anabia and Fiaz, Mustansar and Hassan, Mehdi and Afridi, Tariq Habib and Marwat, Sibghat Ullah and Munir, Farzeen and Ali, Safdar and Naseem, Hannan and Zaheer, Muhammad Zaigham and Ali, Kamran and Sultana, Tangina and Tanoli, Ziaurrehman and Akhter, Naeem},
  journal   = {arXiv preprint},
  year      = {2024},
  note      = {arXiv:2408.17059 [cs]},
  doi       = {10.48550/arXiv.2408.17059},
  url       = {http://arxiv.org/abs/2408.17059},
  keywords  = {self-supervised learning, vision transformers, SSL}
}

@inproceedings{sudarshan2025object,
  title     = {Object Detection using Vision Transformer and Deep Learning for Computer Vision Applications},
  author    = {Sudarshan, S. and Mohana and Ambika, G. and Kavitha, A. and Nataraj, K. and Sudhangowda, B. S.},
  booktitle = {2025 7th International Conference on Intelligent Sustainable Systems (ICISS)},
  pages     = {1524--1529},
  year      = {2025},
  month     = {March},
  doi       = {10.1109/ICISS63372.2025.11076364},
  url       = {https://ieeexplore.ieee.org/document/11076364},
  keywords  = {vision transformer, object detection, CNN comparison}
}

% ============================================================================
% VIT PARA ANOMALY DETECTION INDUSTRIAL
% ============================================================================

@article{zhang2025exploring,
  title     = {Exploring plain ViT features for multi-class unsupervised visual anomaly detection},
  author    = {Zhang, Jiangning and Chen, Xuhai and Wang, Yabiao and Wang, Chengjie and Liu, Yong and Li, Xiangtai and Yang, Ming-Hsuan and Tao, Dacheng},
  journal   = {Computer Vision and Image Understanding},
  volume    = {253},
  pages     = {104308},
  year      = {2025},
  month     = {March},
  publisher = {Elsevier},
  doi       = {10.1016/j.cviu.2025.104308},
  url       = {https://www.sciencedirect.com/science/article/pii/S1077314225000311},
  keywords  = {ViTAD, multi-class anomaly detection, plain ViT, MVTec AD}
}

@article{wang2022defect,
  title     = {Defect Transformer: An Efficient Hybrid Transformer Architecture for Surface Defect Detection},
  author    = {Wang, Junpu and Xu, Guili and Yan, Fuju and Wang, Jinjin and Wang, Zhengsheng},
  journal   = {IEEE Transactions on Instrumentation and Measurement},
  year      = {2022},
  month     = {July},
  note      = {arXiv:2207.08319 [cs]},
  doi       = {10.48550/arXiv.2207.08319},
  url       = {http://arxiv.org/abs/2207.08319},
  keywords  = {hybrid architecture, CNN-transformer, surface defect detection}
}

% ============================================================================
% TRANSFER LEARNING Y FEW-SHOT LEARNING
% ============================================================================

@inproceedings{huang2025semiconductor,
  title     = {Semiconductor SEM Image Defect Classification Using Supervised and Semi-Supervised Learning with Vision Transformers},
  author    = {Huang, Chien-Fu and Sieg, Katherine and Karlinksy, Leonid and Flores, Nash and Sheraw, Rebekah and Zhang, Xin},
  booktitle = {2025 36th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)},
  pages     = {1--5},
  year      = {2025},
  month     = {May},
  organization = {IBM Research},
  note      = {arXiv:2506.03345 [cs]},
  doi       = {10.1109/ASMC64512.2025.11010396},
  url       = {http://arxiv.org/abs/2506.03345},
  keywords  = {DINOv2, few-shot learning, semiconductor defects, transfer learning, industrial application}
}

@book{alber2024evaluating,
  title     = {Evaluating Vision Transformer Models for Visual Quality Control in Industrial Manufacturing},
  author    = {Alber, Miriam and Hönes, Christoph and Baier, Patrick},
  year      = {2024},
  series    = {Lecture Notes in Computer Science},
  volume    = {14950},
  publisher = {Springer},
  note      = {arXiv:2411.14953 [cs]},
  doi       = {10.1007/978-3-031-70381-2},
  url       = {http://arxiv.org/abs/2411.14953},
  keywords  = {benchmarking, ViT evaluation, industrial QC, MVTec AD, BTAD}
}

% ============================================================================
% TÉCNICAS AVANZADAS
% ============================================================================

@article{legia2025consistent,
  title     = {On the Problem of Consistent Anomalies in Zero-Shot Industrial Anomaly Detection},
  author    = {Le-Gia, Tai and Ahn, Jaehyun},
  journal   = {arXiv preprint},
  year      = {2025},
  month     = {October},
  note      = {arXiv:2510.10456 [cs]},
  doi       = {10.48550/arXiv.2510.10456},
  url       = {http://arxiv.org/abs/2510.10456},
  keywords  = {zero-shot, consistent anomalies, CoDeGraph, neighbor-burnout, DINOv2}
}

@article{nafez2025patchguard,
  title     = {PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies},
  author    = {Nafez, Mojtaba and Koochakian, Amirhossein and Maleki, Arad and Habibi, Jafar and Rohban, Mohammad Hossein},
  journal   = {arXiv preprint},
  year      = {2025},
  month     = {June},
  note      = {arXiv:2506.09237 [cs]},
  doi       = {10.48550/arXiv.2506.09237},
  url       = {http://arxiv.org/abs/2506.09237},
  keywords  = {adversarial robustness, pseudo-anomalies, attention mechanisms}
}

% ============================================================================
% REFERENCIAS ADICIONALES RECOMENDADAS (para futuras inclusiones)
% ============================================================================

% Nota: Estas referencias son mencionadas en tu planning original pero no
% están en el JSON actual. Deberías buscarlas y añadirlas cuando las necesites.

% @inproceedings{roth2022patchcore,
%   title     = {Towards Total Recall in Industrial Anomaly Detection},
%   author    = {Roth, Karsten and Pemula, Latha and Zepeda, Joaquin and Schölkopf, Bernhard and Brox, Thomas and Gehler, Peter},
%   booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
%   pages     = {14318--14328},
%   year      = {2022},
%   keywords  = {PatchCore, memory bank, GOLD STANDARD baseline}
% }

% @article{dosovitskiy2021vit,
%   title   = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
%   author  = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and others},
%   journal = {ICLR},
%   year    = {2021},
%   keywords = {ViT original paper}
% }

% @article{oquab2024dinov2,
%   title   = {DINOv2: Learning Robust Visual Features without Supervision},
%   author  = {Oquab, Maxime and Darcet, Timothée and others},
%   journal = {arXiv preprint},
%   year    = {2024},
%   keywords = {DINOv2 original, self-supervised}
% }