üöÄ Implementaci√≥n FASE 2: Opci√≥n 3 (Progressive Unfreezing)
Vamos a estructurar esto para que funcione a la primera. He corregido el error de las transformaciones en los nuevos configs.

1. Estructura de Archivos
Aseg√∫rate de tener estas carpetas creadas:

Bash

demo-Multimodal/fase2_progressive/
‚îú‚îÄ‚îÄ configs/
‚îú‚îÄ‚îÄ models/
‚îî‚îÄ‚îÄ scripts/
2. Los Modelos (Arquitectura Multimodal)
Guarda estos tres archivos en demo-Multimodal/fase2_progressive/models/.

text_encoder.py (Wrapper para CLIP)

Python

import torch
import torch.nn as nn
from transformers import CLIPProcessor, CLIPModel

class TextEncoder(nn.Module):
    def __init__(self, model_name="openai/clip-vit-base-patch32", device="cuda"):
        super().__init__()
        print(f"üì¶ Cargando CLIP ({model_name})...")
        self.model = CLIPModel.from_pretrained(model_name).to(device)
        self.processor = CLIPProcessor.from_pretrained(model_name)
        self.device = device
        
        # Congelar CLIP totalmente
        for param in self.model.parameters():
            param.requires_grad = False
    
    @torch.no_grad()
    def encode_texts(self, text_list):
        inputs = self.processor(text=text_list, return_tensors="pt", 
                               padding=True, truncation=True).to(self.device)
        outputs = self.model.get_text_features(**inputs)
        return outputs / outputs.norm(p=2, dim=-1, keepdim=True)
multimodal_fusion.py (El cerebro de la fusi√≥n)

Python

import torch
import torch.nn as nn
import torch.nn.functional as F

class MultimodalFusionModule(nn.Module):
    def __init__(self, visual_dim=256, text_dim=512, num_classes=6, hidden_dim=256):
        super().__init__()
        
        # Proyecci√≥n visual para igualar dimensiones con texto
        self.visual_proj = nn.Linear(visual_dim, text_dim)
        
        # Cabecera de fusi√≥n que toma la imagen proyectada
        # y aprende a clasificar bas√°ndose en la alineaci√≥n sem√°ntica
        self.fusion_head = nn.Sequential(
            nn.Linear(text_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, num_classes) 
        )
        
        # Temperatura aprendible para escalado
        self.temperature = nn.Parameter(torch.ones([]) * 0.07)

    def forward(self, visual_features, text_embeddings):
        # visual_features: [Batch, Queries, 256]
        # text_embeddings: [NumClasses, 512]
        
        # 1. Alinear espacio visual al textual
        v_proj = self.visual_proj(visual_features) # [B, N, 512]
        
        # 2. Normalizar
        v_norm = F.normalize(v_proj, p=2, dim=-1)
        t_norm = F.normalize(text_embeddings, p=2, dim=-1)
        
        # 3. Similitud Coseno (Atenci√≥n Cruzada impl√≠cita)
        # [B, N, 512] @ [512, Classes] -> [B, N, Classes]
        similarity = torch.matmul(v_norm, t_norm.t()) / self.temperature
        
        # 4. Refinamiento final (Residual o directo)
        # Usamos la proyecci√≥n visual enriquecida para la decisi√≥n final
        logits = self.fusion_head(v_proj)
        
        # Opcional: Sumar similitud directa como bias inductivo
        return logits + similarity
deimv2_multimodal.py (El ensamblaje)

Python

import torch
import torch.nn as nn

class DEIMv2Multimodal(nn.Module):
    def __init__(self, deimv2_model, fusion_module, text_embeddings):
        super().__init__()
        self.deimv2 = deimv2_model
        self.fusion = fusion_module
        self.register_buffer('text_embeddings', text_embeddings)
        
        # Hook para capturar features visuales del decoder
        self._features = []
        self._hook_registered = False
        self._register_hook()

    def _register_hook(self):
        # Buscamos la √∫ltima capa lineal del decoder de DEIMv2
        for name, module in self.deimv2.named_modules():
            if 'decoder.dec_score_head' in name and isinstance(module, nn.Linear):
                module.register_forward_pre_hook(self._hook_fn)
                print(f"‚öì Hook instalado en: {name}")
                self._hook_registered = True
        
        if not self._hook_registered:
            # Fallback para intentar encontrar cualquier cabecera de score
            print("‚ö†Ô∏è Aviso: Buscando hook alternativo...")
            for name, module in self.deimv2.named_modules():
                if 'score_head' in name and isinstance(module, nn.Linear):
                    module.register_forward_pre_hook(self._hook_fn)
                    self._hook_registered = True
                    break

    def _hook_fn(self, module, args):
        # Capturamos la entrada a la capa de clasificaci√≥n (las features visuales puras)
        if isinstance(args[0], torch.Tensor):
            self._features.append(args[0])

    def forward(self, images, targets=None):
        self._features = [] # Limpiar buffer
        
        # 1. Forward del detector base
        outputs = self.deimv2(images, targets)
        
        # 2. Fusi√≥n Multimodal
        if self._features:
            # Tomamos la √∫ltima feature map capturada (salida final del decoder)
            visual_feats = self._features[-1] # [B, N, 256]
            
            # Aplicamos fusi√≥n
            if visual_feats.dim() == 3:
                fused_logits = self.fusion(visual_feats, self.text_embeddings)
                outputs['pred_logits'] = fused_logits
        
        return outputs
3. Configuraciones Corregidas (Sin el error ToTensor)
Guarda en demo-Multimodal/fase2_progressive/configs/.

phase1_warmup.yml (Aqu√≠ arreglamos el KeyError cambiando ToTensor por ConvertPILImage).

YAML

# FASE 1: Warm-up (Solo entrena el m√≥dulo de fusi√≥n)
# Hereda rutas relativas correctas
__include__: [
  '../../../scripts/deimv2_multimodal/configs/deimv2_industrial_defects.yml'
]

output_dir: ./outputs/fase2_progressive_p1

# -----------------------------------------------------------------
# FIX CR√çTICO DE DATALOADER
# Reemplazamos 'ToTensor' (no registrado) por 'ConvertPILImage' (registrado)
# -----------------------------------------------------------------
train_dataloader: 
  dataset: 
    transforms:
      ops:
        - {type: Resize, size: [1024, 1024]}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
        - {type: Normalize, mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}
  shuffle: True
  total_batch_size: 2
  num_workers: 0

val_dataloader:
  dataset:
    transforms:
      ops:
        - {type: Resize, size: [1024, 1024]}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
        - {type: Normalize, mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}
  shuffle: False
  total_batch_size: 2
  num_workers: 0

# -----------------------------------------------------------------
# CONFIGURACI√ìN DE ENTRENAMIENTO
# -----------------------------------------------------------------
optimizer:
  type: AdamW
  lr: 0.0002  # LR inicial para el warmup
  weight_decay: 0.0001

criterion:
  type: DEIMCriterion
  matcher:
    type: HungarianMatcher
    cost_class: 2.0
    cost_bbox: 5.0
    cost_giou: 2.0
  weight_dict:
    loss_class: 2.0
    loss_bbox: 0.0  # Congelado
    loss_giou: 0.0  # Congelado
    loss_vfl: 0.0
    loss_focal: 2.0
  losses: ['focal']

postprocessor:
  type: DEIMPostProcessor
  num_top_queries: 300
  num_classes: 6
  use_focal_loss: True
phase2_finetuning.yml (Para cuando termines la fase 1)

YAML

# FASE 2: Fine-tuning (Descongela parcialmente el detector)
__include__: [ 'phase1_warmup.yml' ]

output_dir: ./outputs/fase2_progressive_p2

optimizer:
  type: AdamW
  lr: 0.00005  # LR m√°s bajo para ajuste fino
4. El Script Maestro (train_progressive.py)
Guarda esto en demo-Multimodal/fase2_progressive/train_progressive.py. Este script maneja la l√≥gica de la Opci√≥n 3, cargando pesos, congelando capas correctamente y ejecutando el bucle.

Python

#!/usr/bin/env python3
import os
import sys
import argparse
import torch
import torch.nn as nn
from pathlib import Path

# --- SETUP PATHS ---
current_file = Path(__file__).resolve()
# Ajustar seg√∫n tu estructura: subir niveles hasta ra√≠z
PROJECT_ROOT = current_file.parent.parent.parent
DEIMV2_PATH = PROJECT_ROOT / "DEIMv2"

if str(DEIMV2_PATH) not in sys.path:
    sys.path.insert(0, str(DEIMV2_PATH))

# --- IMPORTS DEIMv2 (Con registro de m√≥dulos) ---
# Importamos expl√≠citamente para disparar los @register
import engine.data.transforms 
import engine.data.dataset
from engine.core import YAMLConfig

# --- IMPORTS PROPIOS ---
# Ajustamos sys.path para encontrar m√≥dulos locales
sys.path.insert(0, str(current_file.parent))
from models.text_encoder import TextEncoder
from models.multimodal_fusion import MultimodalFusionModule
from models.deimv2_multimodal import DEIMv2Multimodal

# --- PROMPTS ---
TEXT_PROMPTS = [
    "Normal, clean surface without defects",
    "Surface deformation, dent or irregularity",
    "Fracture, crack, broken material or rupture",
    "Scratch, surface abrasion or line mark",
    "Perforation, hole or drilled spot",
    "Contamination, dirt, stain or foreign particle"
]

def train_one_epoch(model, loader, optimizer, criterion, device, epoch):
    model.train()
    model.deimv2.eval() # El detector base siempre en eval para BatchNorms
    
    total_loss = 0
    for i, (images, targets) in enumerate(loader):
        images = images.to(device)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        
        optimizer.zero_grad()
        outputs = model(images, targets)
        
        # Filtrar losses no deseadas
        loss_dict = criterion(outputs, targets)
        loss = sum(l for k, l in loss_dict.items() if k in ['loss_focal', 'loss_ce', 'loss_class'])
        
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        if i % 10 == 0:
            print(f"   Epoch {epoch} | Batch {i}/{len(loader)} | Loss: {loss.item():.4f}")
            
    return total_loss / len(loader)

def main(args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üöÄ Iniciando FASE {args.phase} - Estrategia Progresiva")
    
    # 1. Configuraci√≥n
    cfg = YAMLConfig(args.config)
    
    # 2. Text Embeddings
    print("üìù Generando embeddings de texto...")
    text_enc = TextEncoder(device=device)
    text_embeds = text_enc.encode_texts(TEXT_PROMPTS)
    
    # 3. Modelo Base (DEIMv2)
    print("üèóÔ∏è  Cargando DEIMv2 base...")
    # Truco: instanciamos desde config pero cargamos pesos manualmente
    deim_model = cfg.model.to(device)
    
    # Cargar pesos correctos seg√∫n la fase
    if args.phase == 1:
        # En fase 1 cargamos el best_stg1 de la FASE 1 original
        ckpt_path = PROJECT_ROOT / "scripts/deimv2_multimodal/outputs/deimv2_1024_300epochs/best_stg1.pth"
    else:
        # En fases posteriores, cargamos el resultado de la fase anterior
        prev_phase = args.phase - 1
        ckpt_path = Path(f"./outputs/fase2_progressive_p{prev_phase}/final.pth")
    
    print(f"üìÇ Cargando checkpoint: {ckpt_path}")
    checkpoint = torch.load(ckpt_path, map_location=device)
    
    # Manejo robusto de state_dict
    state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint
    if 'state_dict' in checkpoint: state_dict = checkpoint['state_dict']
    
    # Si cargamos un modelo multimodal previo, hay que limpiar las llaves 'fusion' y 'text'
    # para cargarlo en deim_model puro, o cargarlo directo en el wrapper.
    # Para simplicidad en FASE 1: cargamos en deim puro.
    # Para FASE 2: cargaremos todo.
    
    try:
        deim_model.load_state_dict(state_dict, strict=False)
    except Exception as e:
        print(f"‚ö†Ô∏è Aviso de carga parcial (normal si cambiamos arquitectura): {e}")

    # 4. Ensamble Multimodal
    fusion = MultimodalFusionModule(num_classes=6).to(device)
    model = DEIMv2Multimodal(deim_model, fusion, text_embeds).to(device)
    
    # 5. ESTRATEGIA DE CONGELACI√ìN (El coraz√≥n de la Opci√≥n 3)
    print(f"‚ùÑÔ∏è Aplicando congelaci√≥n para FASE {args.phase}...")
    
    # Congelar todo por defecto
    for p in model.parameters(): p.requires_grad = False
    
    # Descongelar Fusi√≥n (Siempre entrena)
    for p in model.fusion.parameters(): p.requires_grad = True
    
    if args.phase == 1:
        print("   -> Entrenando SOLO Fusi√≥n")
    elif args.phase == 2:
        print("   -> Entrenando Fusi√≥n + Cabeceras de DEIM")
        # Descongelar cabeceras de clasificaci√≥n del detector
        for name, p in model.deimv2.named_parameters():
            if 'score_head' in name or 'class_embed' in name:
                p.requires_grad = True
    
    # Reporte de par√°metros
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"   üìä Par√°metros entrenables: {trainable:,}")

    # 6. Dataloaders (con FIX de ToTensor aplicado en YAML)
    train_loader = cfg.train_dataloader
    criterion = cfg.criterion.to(device)
    
    # Filtro de losses
    if hasattr(criterion, 'aux_loss'): criterion.aux_loss = False
    criterion.losses = ['focal'] # Solo clasificaci√≥n
    
    optimizer = torch.optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=cfg.yaml_cfg['optimizer']['lr']
    )
    
    # 7. Training Loop
    os.makedirs(cfg.yaml_cfg['output_dir'], exist_ok=True)
    epochs = 10 # 10 epochs por fase es suficiente para probar
    
    for epoch in range(epochs):
        avg_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, epoch)
        print(f"üèÅ Epoch {epoch} Final Loss: {avg_loss:.4f}")
        
        # Guardar checkpoint
        torch.save(model.state_dict(), f"{cfg.yaml_cfg['output_dir']}/epoch_{epoch}.pth")
        
    torch.save(model.state_dict(), f"{cfg.yaml_cfg['output_dir']}/final.pth")
    print("‚úÖ Fase completada.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--phase', type=int, required=True, help='1=Warmup, 2=Finetune')
    parser.add_argument('--config', type=str, required=True)
    args = parser.parse_args()
    main(args)
Instrucciones para Ejecutar
Crea los archivos tal cual te los he puesto.

Ejecuta la Fase 1 (Warmup):

Bash

python demo-Multimodal/fase2_progressive/train_progressive.py --phase 1 --config demo-Multimodal/fase2_progressive/configs/phase1_warmup.yml
Resultado esperado:

Ver√°s üì¶ Cargando CLIP....

Ver√°s üì¶ Cargando DEIMv2 base....

NO ver√°s el error de ToTensor porque hemos usado ConvertPILImage.

El entrenamiento empezar√° con una Loss razonable (3.0 - 5.0) y bajar√° r√°pido.

Esta estrategia es mucho m√°s limpia, profesional y adecuada para tu TFG. ¬°Vamos a por ello!